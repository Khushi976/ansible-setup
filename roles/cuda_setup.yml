# # # ---
# # # - hosts: my_servers
# # #   become: yes
# # #   vars:
# # #     cuda_version: "12.2.0"
# # #     cuda_download_url: "https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda_12.2.0_535.54.03_linux.run"
# # #     cuda_installer_filename: "cuda_12.2.0_535.54.03_linux.run"
# # #     temp_download_path: "/tmp/{{ cuda_installer_filename }}"

# # #   tasks:
# # #     - name: Ensure required system dependencies are installed (Debian)
# # #       apt:
# # #         name:
# # #           - wget
# # #           - build-essential
# # #           - gcc
# # #           - make
# # #         state: present
# # #         update_cache: yes
# # #       when: ansible_os_family == 'Debian'

# # #     - name: Ensure required system dependencies are installed (RedHat)
# # #       yum:
# # #         name:
# # #           - wget
# # #           - gcc
# # #           - make
# # #           - kernel-devel
# # #         state: present
# # #       when: ansible_os_family == 'RedHat'

# # #     - name: Create CUDA download directory
# # #       file:
# # #         path: /tmp
# # #         state: directory

# # #     - name: Check if CUDA installer already exists
# # #       stat:
# # #         path: "{{ temp_download_path }}"
# # #       register: cuda_installer

# # #     - name: Download CUDA Installer
# # #       get_url:
# # #         url: "{{ cuda_download_url }}"
# # #         dest: "{{ temp_download_path }}"
# # #         mode: 0755
# # #       when: not cuda_installer.stat.exists

# # #     - name: Disable Nouveau drivers
# # #       copy:
# # #         dest: /etc/modprobe.d/blacklist-nouveau.conf
# # #         content: |
# # #           blacklist nouveau
# # #           options nouveau modeset=0
# # #         mode: 0644

# # #     - name: Update initramfs
# # #       command: update-initramfs -u
# # #       when: ansible_os_family == 'Debian'

# # #     - name: Stop display manager
# # #       systemd:
# # #         name: "{{ 'gdm' if ansible_os_family == 'Debian' else 'lightdm' }}"
# # #         state: stopped
# # #       ignore_errors: yes

# # #     - name: Install CUDA
# # #       shell: "sh {{ temp_download_path }} --silent --toolkit"
# # #       args:
# # #         creates: /usr/local/cuda/bin/nvcc

# # #     - name: Add CUDA to PATH
# # #       blockinfile:
# # #         path: "/etc/profile.d/cuda.sh"
# # #         create: yes
# # #         mode: 0755
# # #         block: |
# # #           export PATH=/usr/local/cuda/bin:$PATH
# # #           export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# # #     - name: Verify CUDA Installation
# # #       shell: /usr/local/cuda/bin/nvcc --version
# # #       register: cuda_version_output
# # #       changed_when: false
# # #       ignore_errors: yes

# # #     - name: Display CUDA Version
# # #       debug:
# # #         var: cuda_version_output.stdout_lines
# # #       when: cuda_version_output.rc == 0

# # #     - name: Clean up installer
# # #       file:
# # #         path: "{{ temp_download_path }}"
# # #         state: absent

# # #   post_tasks:
# # #     - name: Recommend system reboot
# # #       debug:
# # #         msg: "It is recommended to reboot the system to complete CUDA installation."
# # ---
# # - name: Install NVIDIA Drivers and Verify GPU Access
# #   hosts: my_servers
# #   become: yes
# #   tasks:

# #     - name: Update and upgrade system packages
# #       apt:
# #         update_cache: yes
# #         upgrade: yes

# #     - name: Install ubuntu-drivers-common
# #       apt:
# #         name: ubuntu-drivers-common
# #         state: present

# #     - name: Detect recommended NVIDIA driver
# #       command: ubuntu-drivers devices
# #       register: nvidia_recommendation

# #     - name: Install recommended NVIDIA driver
# #       apt:
# #         name: "{{ nvidia_recommendation.stdout_lines | select('search', 'nvidia-driver') | list | first | split()[0] }}"
# #         state: present

# #     - name: Reboot the system
# #       reboot:

# #     - name: Verify NVIDIA installation
# #       command: nvidia-smi
# #       register: nvidia_status
# #       changed_when: false

# #     - debug:
# #         msg: "{{ nvidia_status.stdout }}"

# # - name: Deploy GPU-enabled Docker Container
# #   hosts: localhost
# #   become: yes
# #   tasks:

# #     - name: Install Docker and NVIDIA Container Toolkit
# #       apt:
# #         name:
# #           - docker.io
# #           - nvidia-container-toolkit
# #         state: present

# #     - name: Configure NVIDIA runtime for Docker
# #       copy:
# #         dest: /etc/docker/daemon.json
# #         content: |
# #           {
# #             "runtimes": {
# #               "nvidia": {
# #                 "path": "nvidia-container-runtime",
# #                 "runtimeArgs": []
# #               }
# #             }
# #           }

# #     - name: Restart Docker
# #       systemd:
# #         name: docker
# #         state: restarted

# #     - name: Run GPU-enabled Docker container
# #       docker_container:
# #         name: gpu_container
# #         image: nvidia/cuda:12.1.1-base-ubuntu22.04
# #         runtime: nvidia
# #         env:
# #           NVIDIA_VISIBLE_DEVICES: all
# #           NVIDIA_DRIVER_CAPABILITIES: all
# #         command: ["nvidia-smi"]
# ---
# - name: Install NVIDIA Drivers and Verify GPU Access
#   hosts: localhost
#   become: yes
#   tasks:

#     - name: Update and upgrade system packages
#       apt:
#         update_cache: yes
#         upgrade: yes

#     - name: Install ubuntu-drivers-common
#       apt:
#         name: ubuntu-drivers-common
#         state: present

#     - name: Detect recommended NVIDIA driver
#       shell: "ubuntu-drivers devices | grep -oP 'nvidia-driver-\d+' | head -n 1"
#       register: nvidia_recommendation
#       changed_when: false

#     - name: Install recommended NVIDIA driver
#       apt:
#         name: "{{ nvidia_recommendation.stdout }}"
#         state: present

#     - name: Reboot the system
#       reboot:

#     - name: Verify NVIDIA installation
#       command: nvidia-smi
#       register: nvidia_status
#       changed_when: false

#     - debug:
#         msg: "{{ nvidia_status.stdout }}"

# - name: Deploy GPU-enabled Docker Container
#   hosts: localhost
#   become: yes
#   tasks:

#     - name: Install Docker and NVIDIA Container Toolkit
#       apt:
#         name:
#           - docker.io
#           - nvidia-container-toolkit
#         state: present

#     - name: Configure NVIDIA runtime for Docker
#       copy:
#         dest: /etc/docker/daemon.json
#         content: |
#           {
#             "runtimes": {
#               "nvidia": {
#                 "path": "nvidia-container-runtime",
#                 "runtimeArgs": []
#               }
#             }
#           }

#     - name: Restart Docker
#       systemd:
#         name: docker
#         state: restarted

#     - name: Run GPU-enabled Docker container
#       docker_container:
#         name: gpu_container
#         image: nvidia/cuda:12.1.1-base-ubuntu22.04
#         runtime: nvidia
#         env:
#           NVIDIA_VISIBLE_DEVICES: all
#           NVIDIA_DRIVER_CAPABILITIES: all
#         command: ["nvidia-smi"]

# ---
# - name: Install NVIDIA Drivers and Verify GPU Access
#   hosts: my_servers
#   become: yes
#   tasks:

#     - name: Update and upgrade system packages
#       apt:
#         update_cache: yes
#         upgrade: yes

#     - name: Install ubuntu-drivers-common
#       apt:
#         name: ubuntu-drivers-common
#         state: present

#     - name: Detect recommended NVIDIA driver
#       shell: "ubuntu-drivers devices | grep -oE 'nvidia-driver-[0-9]+' | head -n 1"
#       register: nvidia_recommendation
#       changed_when: false

#     - name: Install recommended NVIDIA driver
#       apt:
#         name: "{{ nvidia_recommendation.stdout }}"
#         state: present

#     - name: Reboot the system
#       reboot:

#     - name: Verify NVIDIA installation
#       command: nvidia-smi
#       register: nvidia_status
#       changed_when: false

#     - debug:
#         msg: "{{ nvidia_status.stdout }}"

# - name: Deploy GPU-enabled Docker Container
#   hosts: my_servers
#   become: yes
#   tasks:

#     - name: Install Docker and NVIDIA Container Toolkit
#       apt:
#         name:
#           - docker.io
#           - nvidia-container-toolkit
#         state: present

#     - name: Configure NVIDIA runtime for Docker
#       copy:
#         dest: /etc/docker/daemon.json
#         content: |
#           {
#             "runtimes": {
#               "nvidia": {
#                 "path": "nvidia-container-runtime",
#                 "runtimeArgs": []
#               }
#             }
#           }

#     - name: Restart Docker
#       systemd:
#         name: docker
#         state: restarted

#     - name: Run GPU-enabled Docker container
#       docker_container:
#         name: gpu_container
#         image: nvidia/cuda:12.1.1-base-ubuntu22.04
#         runtime: nvidia
#         env:
#           NVIDIA_VISIBLE_DEVICES: all
#           NVIDIA_DRIVER_CAPABILITIES: all
#         command: ["nvidia-smi"]
# ---
# - name: Install NVIDIA Drivers and Verify GPU Access
#   hosts: my_servers
#   become: yes
#   tasks:

#     # - name: Update and upgrade system packages
#     #   apt:
#     #     update_cache: yes
#     #     upgrade: yes

#     - name: Install ubuntu-drivers-common
#       apt:
#         name: ubuntu-drivers-common
#         state: present

#     - name: Detect recommended NVIDIA driver
#       shell: "ubuntu-drivers devices | grep -oE 'nvidia-driver-[0-9]+' | head -n 1"
#       register: nvidia_recommendation
#       changed_when: false

#     # - name: Install recommended NVIDIA driver
#     #   apt:
#     #     name: "{{ nvidia_recommendation.stdout }}"
#     #     msg: "{{ nvidia_recommendation.stdout }}"

#     #     state: present
#     - name: Display recommended NVIDIA driver
#       debug:
#         msg: "Installing NVIDIA driver: {{ nvidia_recommendation.stdout }}"

#     - name: Install recommended NVIDIA driver
#       apt:
#         name: "{{ nvidia_recommendation.stdout }}"
#         state: present



#     # - name: Reboot the system
#     #   reboot:

#     # - name: Verify NVIDIA installation
#     #   command: nvidia-smi
#     #   register: nvidia_status
#     #   changed_when: false

#     # - debug:
#     #     msg: "{{ nvidia_status.stdout }}"

# - name: Deploy GPU-enabled Docker Container
#   hosts: my_servers
#   become: yes
#   tasks:

#     - name: Remove conflicting containerd package
#       apt:
#         name:
#           - docker.io
#           - docker-doc
#           - docker-compose
#           - docker-compose-v2
#           - podman-docker
#           - containerd
#           - runc
#         state: absent

#     - name: Install Docker and NVIDIA Container Toolkit
#       apt:
#         name:
#           - docker.io
#           - nvidia-container-toolkit
#         state: present

#     - name: Configure NVIDIA runtime for Docker
#       copy:
#         dest: /etc/docker/daemon.json
#         content: |
#           {
#             "runtimes": {
#               "nvidia": {
#                 "path": "nvidia-container-runtime",
#                 "runtimeArgs": []
#               }
#             }
#           }

#     - name: Restart Docker
#       systemd:
#         name: docker
#         state: restarted

#     - name: Run GPU-enabled Docker container
#       docker_container:
#         name: gpu_container
#         image: nvidia/cuda:12.1.1-base-ubuntu22.04
#         runtime: nvidia
#         env:
#           NVIDIA_VISIBLE_DEVICES: all
#           NVIDIA_DRIVER_CAPABILITIES: all
#         command: ["nvidia-smi"]
---
- name: Install NVIDIA Drivers and Verify GPU Access
  hosts: my_servers
  become: yes
  tasks:

    # - name: Update and upgrade system packages
    #   apt:
    #     update_cache: yes
    #     upgrade: yes

    - name: Install ubuntu-drivers-common
      apt:
        name: ubuntu-drivers-common
        state: present

    - name: Detect recommended NVIDIA driver
      shell: "ubuntu-drivers devices | grep -oE 'nvidia-driver-[0-9]+' | head -n 1"
      register: nvidia_recommendation
      changed_when: false

    - name: Display recommended NVIDIA driver
      debug:
        msg: "Installing NVIDIA driver: {{ nvidia_recommendation.stdout }}"

    - name: Install recommended NVIDIA driver
      apt:
        name: "{{ nvidia_recommendation.stdout }}"
        state: present

    - name: Reboot the system to apply NVIDIA driver changes
      reboot:

    - name: Verify NVIDIA installation
      command: nvidia-smi
      register: nvidia_status
      changed_when: false

    - name: Display NVIDIA installation output
      debug:
        msg: "{{ nvidia_status.stdout }}"


# - name: Deploy GPU-enabled Docker Container
#   hosts: my_servers
#   become: yes
#   tasks:

#     - name: Remove conflicting container packages
#       apt:
#         name:
#           - docker.io
#           - docker-doc
#           - docker-compose
#           - docker-compose-v2
#           - podman-docker
#           - containerd
#           - runc
#         state: absent

#     - name: Install Docker and NVIDIA Container Toolkit
#       apt:
#         name:
#           - docker.io
#           - nvidia-container-toolkit
#         state: present

#     - name: Configure NVIDIA runtime for Docker
#       copy:
#         dest: /etc/docker/daemon.json
#         content: |
#           {
#             "runtimes": {
#               "nvidia": {
#                 "path": "nvidia-container-runtime",
#                 "runtimeArgs": []
#               }
#             }
#           }
# - name: Deploy GPU-enabled Docker Container
#   hosts: my_servers
#   become: yes
#   tasks:

#     - name: Unhold all held packages (if any)
#       shell: "dpkg --get-selections | grep hold | awk '{print $1}' | xargs -r sudo apt-mark unhold"
#       changed_when: false

#     - name: Remove conflicting container packages
#       apt:
#         name:
#           - docker.io
#           - docker-doc
#           - docker-compose
#           - docker-compose-v2
#           - podman-docker
#           - containerd
#           - containerd.io
#           - runc
#         state: absent
#         purge: yes
#       ignore_errors: yes

#     - name: Clean up and fix broken dependencies
#       shell: |
#         sudo apt-get clean
#         sudo apt-get autoremove -y
#         sudo apt-get update --fix-missing
#         sudo apt-get install -f -y
#       changed_when: false

#     - name: Install Docker and NVIDIA Container Toolkit
#       apt:
#         name:
#           - docker.io
#           - nvidia-container-toolkit
#         state: present
#         update_cache: yes
- name: Fix MongoDB GPG Key Issue and Install Docker with NVIDIA Toolkit
  hosts: my_servers
  become: yes
  tasks:

    - name: Remove MongoDB repository
      file:
        path: "/etc/apt/sources.list.d/mongodb-org-7.0.list"
        state: absent

    - name: Remove old MongoDB GPG keys
      file:
        path: "/etc/apt/trusted.gpg.d/mongodb-server-6.0.asc"
        state: absent

    - name: Clean up APT
      shell: |
        sudo apt-get clean
        sudo rm -rf /var/lib/apt/lists/*
      changed_when: false

    - name: Update package lists
      apt:
        update_cache: yes

    - name: Remove conflicting container packages
      apt:
        name:
          - docker.io
          - docker-doc
          - docker-compose
          - docker-compose-v2
          - podman-docker
          - containerd
          - containerd.io
          - runc
        state: absent
        purge: yes
      ignore_errors: yes

    - name: Fix broken dependencies
      shell: "sudo apt-get install -f -y"
      changed_when: false

    - name: Install Docker and NVIDIA Container Toolkit
      apt:
        name:
          - docker.io
          - nvidia-container-toolkit
        state: present
        update_cache: yes


    - name: Restart Docker to apply configuration
      systemd:
        name: docker
        state: restarted



    - name: Run GPU-enabled Docker container
      docker_container:
        name: gpu_container
        image: nvidia/cuda:12.1.1-base-ubuntu22.04
        runtime: nvidia
        env:
          NVIDIA_VISIBLE_DEVICES: all
          NVIDIA_DRIVER_CAPABILITIES: all
        command: ["nvidia-smi"]
      register: gpu_container_output

    - name: Display GPU container output
      debug:
        msg: "{{ gpu_container_output.container.Config.Cmd | default('No output captured') }}"
